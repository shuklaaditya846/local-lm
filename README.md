# Local LLM Chat App (Flutter)

A cross-platform chat application built with Flutter that enables users to have AI-powered conversations offline by running local large language models (LLMs) entirely on-device. This app provides a secure and private chatting experience without the need for external servers or internet connectivity.

## Features

- Runs state-of-the-art LLM models locally for fast, responsive interactions
- Supports multiple LLM backends for flexibility and customization
- Intuitive, user-friendly chat interface with real-time context-aware responses
- Ensures user privacy by keeping all data and inference on the device
- Cross-platform support for mobile and desktop environments

## Technology Stack

- Flutter (Dart) for cross-platform UI and app architecture
- Local LLM integration (e.g., Ollama, llama.cpp)
- On-device model inference for offline AI chat

## Usage

1. Install the app on your device
2. Choose or download supported local LLM models
3. Start chatting naturally without internet dependency
4. Manage chat history and context securely on-device
